# ── LLM (GitHub Models via Azure AI Inference) ──────────────────────────
# Get your token from: https://github.com/settings/tokens
GITHUB_TOKEN="your_github_token_here"
LLM_MODEL="openai/gpt-4o-mini"
LLM_ENDPOINT="https://models.github.ai/inference"

# ── Device ────────────────────────────────────────────────────────────────
# "auto" detects GPU automatically, or force "cpu" / "cuda"
DEVICE="auto"

# ── Whisper ───────────────────────────────────────────────────────────────
# Model sizes (smallest→largest): tiny | base | small | medium | large-v2
# Larger = more accurate but slower; "base" is a good CPU default
WHISPER_MODEL_SIZE="base"
WHISPER_LANGUAGE="en"

# ── Storage ───────────────────────────────────────────────────────────────
STORAGE_PATH="./jobs"
MAX_UPLOAD_SIZE_MB=500

# ── Editing Thresholds ────────────────────────────────────────────────────
PAUSE_MIN_DURATION=0.8        # minimum gap (s) to flag as a pause
PAUSE_KEEP_DURATION=0.3       # how much pause to keep after trimming
SIMILARITY_THRESHOLD=0.82     # cosine similarity threshold for duplicate detection
MIN_SEGMENT_SCORE=0.4         # segments below this score are removed
CUT_PADDING_MS=50             # micro-padding around each cut boundary (ms)

# ── Output Codec ─────────────────────────────────────────────────────────
OUTPUT_VIDEO_CODEC="libx264"
OUTPUT_AUDIO_CODEC="aac"
OUTPUT_CRF=23
OUTPUT_PRESET="medium"

# ── Debug ─────────────────────────────────────────────────────────────────
DEBUG=false
